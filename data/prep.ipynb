{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (1.40.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: transformers in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (5.4.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (5.28.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (18.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from datasets) (3.11.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.5.2 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.17.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kalee\\desktop\\wisdom_of_crowd_of_llms\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit pandas numpy transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Load summaries JSON\n",
    "import json\n",
    "# Load the dataset from its Hugging Face path\n",
    "from datasets import load_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 Processed and saved the first 30,000 rows to fingpt_headline_cls.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the fingpt-headline-cls dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"ZixuanKe/fingpt-headline-cls\")\n",
    "\n",
    "# Select the first 10,000 rows\n",
    "data = dataset['train'][:30000]\n",
    "data = data['messages']\n",
    "\n",
    "# Function to extract the headline and label\n",
    "def process_data(data):\n",
    "    processed = []\n",
    "    for entry in data:\n",
    "        # Extract the user content and assistant response\n",
    "        prompt = entry[0][\"content\"]  # Access the user message\n",
    "\n",
    "        # Add to processed data\n",
    "        processed.append({\"imgname\":None,\"query\": prompt, \"modality\": \"text\"})\n",
    "\n",
    "    return processed\n",
    "\n",
    "# Process the first 10,000 rows\n",
    "processed_data = process_data(data)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(processed_data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"fingpt_headline_cls.csv\", index=False)\n",
    "\n",
    "print(\"Dataset 1 Processed and saved the first 30,000 rows to fingpt_headline_cls.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2 converted and saved as chartqa_without_images.csv\n"
     ]
    }
   ],
   "source": [
    "# Load ChartQA dataset from its Hugging Face path\n",
    "dataset = load_dataset(\"ahmed-masry/chartqa_without_images\")\n",
    "\n",
    "# Select the first 10,000 rows\n",
    "data = dataset[\"train\"][:30000]\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop(columns=['label','type'])\n",
    "df[\"modality\"] = \"multimodal\"\n",
    "# Save to CSV\n",
    "df.to_csv(\"chartqa_without_images.csv\", index=False)\n",
    "\n",
    "print(\"Dataset 2 converted and saved as chartqa_without_images.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  imgname                                              query  \\\n",
      "0                     NaN  Examine the news headline and decide if it inc...   \n",
      "1                     NaN  Does the news headline talk about price going ...   \n",
      "2                     NaN  Review the news headline and determine if it r...   \n",
      "3                     NaN  Examine the news headline and decide if it inc...   \n",
      "4                     NaN  Assess if the news headline touches on price i...   \n",
      "...                   ...                                                ...   \n",
      "58289    two_col_2837.png  What percentage of Indonesia's GDP did the man...   \n",
      "58290   two_col_21016.png  What was Electronic Arts' net income in the fo...   \n",
      "58291   two_col_40682.png  What percentage of Sweden's average earnings d...   \n",
      "58292  two_col_100676.png  What was the player salary of the Brooklyn Net...   \n",
      "58293   two_col_80433.png  What was the highest monthly sales of cannabis...   \n",
      "\n",
      "         modality  \n",
      "0            text  \n",
      "1            text  \n",
      "2            text  \n",
      "3            text  \n",
      "4            text  \n",
      "...           ...  \n",
      "58289  multimodal  \n",
      "58290  multimodal  \n",
      "58291  multimodal  \n",
      "58292  multimodal  \n",
      "58293  multimodal  \n",
      "\n",
      "[58294 rows x 3 columns]\n",
      "All datasets combined and saved as combined_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Load all individual datasets\n",
    "df1 = pd.read_csv(\"fingpt_headline_cls.csv\")\n",
    "df2 = pd.read_csv(\"chartqa_without_images.csv\")\n",
    "\n",
    "# Combine all datasets\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "print(combined_df[:-5])\n",
    "\n",
    "# Save the combined dataset as CSV\n",
    "combined_df.to_csv(\"combined_dataset.csv\", index=False)\n",
    "\n",
    "print(\"All datasets combined and saved as combined_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kalee\\Desktop\\wisdom_of_crowd_of_LLMs\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kalee\\.cache\\huggingface\\hub\\datasets--ahmed-masry--ChartQA. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 28299/28299 [00:17<00:00, 1606.28 examples/s]\n",
      "Generating val split: 100%|██████████| 1920/1920 [00:01<00:00, 1894.08 examples/s]\n",
      "Generating test split: 100%|██████████| 2500/2500 [00:00<00:00, 4050.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 3 converted and saved as chart_to_text.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to the Chart-to-text dataset\n",
    "dataset = load_dataset(\"ahmed-masry/ChartQA\")\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "# Rename columns and save to CSV\n",
    "df = df.rename(columns={\"input_text\": \"text\", \"output_text\": \"label\", \"image_path\": \"image_path\"})\n",
    "df[\"modality\"] = \"multimodal\"  # Add the modality column with \"modality\" as the value\n",
    "df.head(1000).to_csv(\"chartQA.csv\", index=False)\n",
    "\n",
    "print(\"Dataset 3 converted and saved as chart_to_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the UniChart dataset from its Hugging Face path\n",
    "dataset = load_dataset(\"ahmed-masry/unichart-pretrain-data\")\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "# Rename columns and save to CSV\n",
    "df = df.rename(columns={\"input_text\": \"text\", \"output_text\": \"label\", \"image_path\": \"image_path\"})\n",
    "df[\"modality\"] = \"multimodal\"  # Add the modality column with \"modality\" as the value\n",
    "df.to_csv(\"unichart_pretrain_data.csv\", index=False)\n",
    "\n",
    "print(\"Dataset 4 converted and saved as unichart_pretrain_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all individual datasets\n",
    "df1 = pd.read_csv(\"fingpt_headline_cls.csv\")\n",
    "df2 = pd.read_csv(\"chartqa_without_images.csv\")\n",
    "\n",
    "# Combine all datasets\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the combined dataset as CSV\n",
    "combined_df.to_csv(\"combined_dataset.csv\", index=False)\n",
    "\n",
    "print(\"All datasets combined and saved as combined_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
