{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install streamlit pandas numpy transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Load summaries JSON\n",
    "import json\n",
    "# Load the dataset from its Hugging Face path\n",
    "from datasets import load_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 Processed and saved the first 20,000 rows to fingpt_headline_cls/train.csv\n",
      "Dataset 1 Processed and saved the next 5,000 rows to fingpt_headline_cls/val.csv\n",
      "Dataset 1 Processed and saved the first 5,000 rows to fingpt_headline_cls/test.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the fingpt-headline-cls dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"ZixuanKe/fingpt-headline-cls\")\n",
    "\n",
    "# Select the first 10,000 rows\n",
    "train_data = dataset['train'][:20000]\n",
    "val_data = dataset['train'][20001:25000]\n",
    "test_data = dataset['test'][:2500]\n",
    "\n",
    "train_data = train_data['messages']\n",
    "val_data = val_data['messages']\n",
    "test_data = test_data['messages']\n",
    "\n",
    "# Function to extract the headline and label\n",
    "def process_data(data):\n",
    "    processed = []\n",
    "    for entry in data:\n",
    "        # Extract the user content and assistant response\n",
    "        prompt = entry[0][\"content\"]  # Access the user message\n",
    "        label  = entry[1][\"content\"]  #access true label\n",
    "\n",
    "        # Add to processed data\n",
    "        processed.append({\"imgname\":None,\"query\": prompt, \"label\":label, \"modality\": \"text\"})\n",
    "\n",
    "    return processed\n",
    "\n",
    "# Process the first 10,000 rows\n",
    "processed_data_train = process_data(train_data)\n",
    "processed_data_val = process_data(val_data)\n",
    "processed_data_test = process_data(test_data)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_train = pd.DataFrame(processed_data_train)\n",
    "df_val = pd.DataFrame(processed_data_val)\n",
    "df_test = pd.DataFrame(processed_data_test)\n",
    "\n",
    "# Save to CSV\n",
    "df_train.to_csv(\"fingpt_headline_cls/train.csv\", index=False)\n",
    "print(\"Dataset 1 Processed and saved the first 20,000 rows to fingpt_headline_cls/train.csv\")\n",
    "\n",
    "df_val.to_csv(\"fingpt_headline_cls/val.csv\", index=False)\n",
    "print(\"Dataset 1 Processed and saved the next 5,000 rows to fingpt_headline_cls/val.csv\")\n",
    "\n",
    "df_test.to_csv(\"fingpt_headline_cls/test.csv\", index=False)\n",
    "print(\"Dataset 1 Processed and saved the first 5,000 rows to fingpt_headline_cls/test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2 converted and saved\n"
     ]
    }
   ],
   "source": [
    "# Load ChartQA dataset from its Hugging Face path\n",
    "dataset = load_dataset(\"ahmed-masry/chartqa_without_images\")\n",
    "\n",
    "# Select the first 10,000 rows\n",
    "train_data = dataset[\"train\"][:20000]\n",
    "val_data = dataset[\"val\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_train = pd.DataFrame(train_data)\n",
    "df_val = pd.DataFrame(val_data)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "df_train[\"modality\"] = \"multimodal\"\n",
    "df_val[\"modality\"] = \"multimodal\"\n",
    "df_test[\"modality\"] = \"multimodal\"\n",
    "\n",
    "# Save to CSV\n",
    "df_train.to_csv(\"chartqa/train.csv\", index=False)\n",
    "df_val.to_csv(\"chartqa/val.csv\", index=False)\n",
    "df_test.to_csv(\"chartqa/test.csv\", index=False)\n",
    "\n",
    "print(\"Dataset 2 converted and saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 3 converted and saved\n"
     ]
    }
   ],
   "source": [
    "# Load ChartQA dataset from its Hugging Face path\n",
    "dataset = load_dataset(\"TIGER-Lab/MathInstruct\")\n",
    "\n",
    "# Select the first 10,000 rows\n",
    "test_data = dataset[\"train\"][:2500]\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "df_test[\"modality\"] = \"math\"\n",
    "\n",
    "df_test.rename(columns={'source': 'imgname', 'output': 'label', 'instruction':'query'}, inplace=True)\n",
    "\n",
    "df_test['imgname']=None\n",
    "\n",
    "# Get current column names\n",
    "current_columns = df_test.columns.tolist()\n",
    "\n",
    "# Swap 2nd and 3rd columns\n",
    "current_columns[1], current_columns[2] = current_columns[2], current_columns[1]\n",
    "\n",
    "# Reorder the DataFrame\n",
    "df_test = df_test[current_columns]\n",
    "\n",
    "# Save to CSV\n",
    "df_test.to_csv(\"math/test.csv\", index=False)\n",
    "\n",
    "print(\"Dataset 3 converted and saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2500\n",
      "2500\n",
      "7500\n",
      "     imgname                                              query  \\\n",
      "0        NaN  Examine the news headline and decide if it inc...   \n",
      "1        NaN  Let me know if the news headline talks about p...   \n",
      "2        NaN  Consider the news headline - does it concern p...   \n",
      "3        NaN  Please determine if the news headline addresse...   \n",
      "4        NaN  In the context of the news headline, is price ...   \n",
      "...      ...                                                ...   \n",
      "7490     NaN  Jerry has an interesting novel he borrowed fro...   \n",
      "7491     NaN  A store has an 8% discount on all items. If Sh...   \n",
      "7492     NaN  A man walks at a speed of 7 km/hr and runs at ...   \n",
      "7493     NaN  The diagonal of a rectangle is 41 cm and its a...   \n",
      "7494     NaN  A fruit seller had some oranges. He sells 40% ...   \n",
      "\n",
      "                                                  label modality type  \n",
      "0                                                    No     text  NaN  \n",
      "1                                                    No     text  NaN  \n",
      "2                                                    No     text  NaN  \n",
      "3                                                    No     text  NaN  \n",
      "4                                                    No     text  NaN  \n",
      "...                                                 ...      ...  ...  \n",
      "7490  When Jerry reads 30 pages on Saturday and 20 p...     math  NaN  \n",
      "7491  The price that Shara paid is only 100% - 8% = ...     math  NaN  \n",
      "7492  Let's think about the multi-choice question.\\n...     math  NaN  \n",
      "7493  Let's think about the multi-choice question.\\n...     math  NaN  \n",
      "7494  Let's solve the multi-choice question step by ...     math  NaN  \n",
      "\n",
      "[7495 rows x 5 columns]\n",
      "All datasets combined and saved as combined_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Load all individual datasets\n",
    "df1_train = pd.read_csv(\"fingpt_headline_cls/train.csv\")\n",
    "df2_train = pd.read_csv(\"chartqa/train.csv\")\n",
    "\n",
    "df1_val = pd.read_csv(\"fingpt_headline_cls/val.csv\")\n",
    "df2_val = pd.read_csv(\"chartqa/val.csv\")\n",
    "\n",
    "df1_test = pd.read_csv(\"fingpt_headline_cls/test.csv\")\n",
    "print(len(df1_test))\n",
    "df2_test = pd.read_csv(\"chartqa/test.csv\")\n",
    "print(len(df2_test))\n",
    "df3_test = pd.read_csv(\"math/test.csv\")\n",
    "print(len(df3_test))\n",
    "\n",
    "# Combine all datasets\n",
    "combined_df_train = pd.concat([df1_train, df2_train], ignore_index=True)\n",
    "combined_df_val = pd.concat([df1_val, df2_val], ignore_index=True)\n",
    "combined_df_test = pd.concat([df1_test, df2_test, df3_test], ignore_index=True)\n",
    "\n",
    "print(len(combined_df_test))\n",
    "\n",
    "print(combined_df_test[:-5])\n",
    "\n",
    "# Save the combined dataset as CSV\n",
    "combined_df_train.to_csv(\"merged_data/train.csv\", index=False)\n",
    "combined_df_val.to_csv(\"merged_data/val.csv\", index=False)\n",
    "combined_df_test.to_csv(\"merged_data/test.csv\", index=False)\n",
    "\n",
    "print(\"All datasets combined and saved as combined_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (Conda 2024.06) [python/3.12]",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
